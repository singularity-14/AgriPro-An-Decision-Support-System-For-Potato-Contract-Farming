{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#  Stand Count Analysis\n",
        "\n",
        "# Libraries\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sentinelhub\n",
        "from sentinelhub import SHConfig\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "from matplotlib.colors import PowerNorm\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import json\n",
        "import memory_profiler\n",
        "import rasterio\n",
        "from rasterio.mask import mask as rio_mask\n",
        "from shapely.geometry import Point,Polygon\n",
        "from osgeo import gdal\n",
        "import shutil\n",
        "from sentinelhub import (\n",
        "        CRS,\n",
        "        BBox,\n",
        "        DataCollection,\n",
        "        DownloadRequest,\n",
        "        MimeType,\n",
        "        MosaickingOrder,\n",
        "        SentinelHubDownloadClient,\n",
        "        SentinelHubRequest,\n",
        "        bbox_to_dimensions,\n",
        ")\n",
        "\n",
        "\n",
        "def standcount(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing):\n",
        "\n",
        "    with open('/content/drive/MyDrive/internship/B - with GDAL/python_services_config.json','r') as config_file:\n",
        "        get_configuration = json.load(config_file)\n",
        "\n",
        "    config_data_stand_count=get_configuration['potato_stand_count']\n",
        "    config_data_main=get_configuration['main']\n",
        "\n",
        "    config = SHConfig()\n",
        "\n",
        "    config.sh_client_id = config_data_main[\"sh_client_id\"]\n",
        "    config.sh_client_secret = config_data_main[\"sh_client_secret\"]\n",
        "    config.save()\n",
        "\n",
        "    today=datetime.now()\n",
        "    save_date=today.strftime(\"%Y-%m-%d-%H-%m-%s\")\n",
        "\n",
        "    home_directory = os.path.expanduser(\"~\")\n",
        "    cc_output_directory = os.path.join(home_directory,config_data_stand_count['output_folder'])\n",
        "    os.makedirs(cc_output_directory, exist_ok=True)\n",
        "\n",
        "    # date\n",
        "    def extract_start_date(analysis_date):\n",
        "        e=datetime.strptime(analysis_date,'%Y-%m-%d')\n",
        "        s=e-timedelta(7)\n",
        "        start_date=s.strftime('%Y-%m-%d')\n",
        "        return start_date\n",
        "\n",
        "    start_date=extract_start_date(analysis_date)\n",
        "    end_date=analysis_date\n",
        "\n",
        "    # extract the spacing format 25*26m2\n",
        "    number=input_spacing.split(\"*\")\n",
        "    num1=float(number[0])\n",
        "    num2=float(number[1])\n",
        "    spacing=num1+num2\n",
        "\n",
        "    # boudning box\n",
        "    min_x = min(p[0] for p in polygon_c)\n",
        "    max_x = max(p[0] for p in polygon_c)\n",
        "    min_y = min(p[1] for p in polygon_c)\n",
        "    max_y = max(p[1] for p in polygon_c)\n",
        "\n",
        "\n",
        "    bounding_box = (min_x, min_y, max_x, max_y)\n",
        "    resolution = 10\n",
        "    betsiboka_bbox = BBox(bbox=bounding_box, crs=CRS.WGS84)\n",
        "    betsiboka_size = bbox_to_dimensions(betsiboka_bbox, resolution=resolution)\n",
        "\n",
        "    # print(f\"Image shape at {resolution} m resolution: {betsiboka_size} pixels\")\n",
        "\n",
        "    evalscript_all_bands = \"\"\"\n",
        "        //VERSION=3\n",
        "        function setup() {\n",
        "            return {\n",
        "                input: [{\n",
        "                    bands: [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"],\n",
        "                    units: \"DN\"\n",
        "                }],\n",
        "                output: {\n",
        "                    bands: 13,\n",
        "                    sampleType: \"INT16\"\n",
        "                }\n",
        "            };\n",
        "        }\n",
        "\n",
        "        function evaluatePixel(sample) {\n",
        "            return [sample.B01,\n",
        "                    sample.B02,\n",
        "                    sample.B03,\n",
        "                    sample.B04,\n",
        "                    sample.B05,\n",
        "                    sample.B06,\n",
        "                    sample.B07,\n",
        "                    sample.B08,\n",
        "                    sample.B8A,\n",
        "                    sample.B09,\n",
        "                    sample.B10,\n",
        "                    sample.B11,\n",
        "                    sample.B12];\n",
        "        }\n",
        "    \"\"\"\n",
        "\n",
        "    request_all_bands = SentinelHubRequest(\n",
        "        evalscript=evalscript_all_bands,\n",
        "        data_folder=config_data_main[\"data_output_folder\"],\n",
        "        input_data=[\n",
        "            SentinelHubRequest.input_data(\n",
        "                data_collection=DataCollection.SENTINEL2_L1C,\n",
        "                time_interval=(str(start_date),str(end_date)),\n",
        "                mosaicking_order=MosaickingOrder.LEAST_CC,\n",
        "            )\n",
        "        ],\n",
        "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
        "        bbox=betsiboka_bbox,\n",
        "        size=betsiboka_size,\n",
        "        config=config,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "\n",
        "        all_bands_response = request_all_bands.get_data()\n",
        "\n",
        "        # stacked image\n",
        "        # %%time\n",
        "        all_bands_img = request_all_bands.get_data(save_data=True)\n",
        "\n",
        "        for folder, _, filenames in os.walk(request_all_bands.data_folder):\n",
        "            for filename in filenames:\n",
        "                file_path = os.path.join(folder, filename)\n",
        "\n",
        "                if filename.endswith(\".tif\") or filename.endswith(\".tiff\"):\n",
        "\n",
        "                    try:\n",
        "                      # clip the raster for getting the image with nan pixels\n",
        "                      selected_bands=[2,3,4,8]\n",
        "                      def clip_and_remove_zero_pixels(file_a,path_b,polygon_c):\n",
        "                          with rasterio.open(file_a) as src:\n",
        "                              polygon = Polygon(polygon_c)\n",
        "\n",
        "                              out_image, out_transform = rio_mask(src, [polygon], crop=True)\n",
        "\n",
        "                              out_meta = src.meta.copy()\n",
        "                              out_meta.update({\"driver\": \"GTiff\",\n",
        "                                              \"height\": out_image.shape[1],\n",
        "                                              \"width\": out_image.shape[2],\n",
        "                                              \"transform\": out_transform})\n",
        "\n",
        "                          clipped_raster_path = config_data_main[\"data_output_folder\"]+\"file.tiff\"\n",
        "                          with rasterio.open(clipped_raster_path, \"w\", **out_meta) as dest:\n",
        "                              dest.write(out_image)\n",
        "\n",
        "                          src_ds = gdal.Open(clipped_raster_path)\n",
        "                          if src_ds is None:\n",
        "                              print(\"Failed to open the clipped raster file.\")\n",
        "                              return\n",
        "\n",
        "                          cols = src_ds.RasterXSize\n",
        "                          rows = src_ds.RasterYSize\n",
        "                          bands = src_ds.RasterCount\n",
        "\n",
        "                          driver = gdal.GetDriverByName(\"GTiff\")\n",
        "                          dst_ds = driver.Create(path_b, cols, rows, bands, gdal.GDT_Float32)\n",
        "\n",
        "                          dst_ds.SetProjection(src_ds.GetProjection())\n",
        "                          dst_ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
        "\n",
        "                          for band_idx in range(1, bands + 1):\n",
        "                              band = src_ds.GetRasterBand(band_idx)\n",
        "                              band_array = band.ReadAsArray()\n",
        "\n",
        "                              mask_array = (band_array == -99999)\n",
        "\n",
        "                              masked_band_array = np.where(mask_array, np.nan, band_array)\n",
        "\n",
        "                              dst_band = dst_ds.GetRasterBand(band_idx)\n",
        "                              dst_band.WriteArray(masked_band_array)\n",
        "                          src_ds = None\n",
        "                          dst_ds = None\n",
        "                          os.remove(clipped_raster_path)\n",
        "\n",
        "                      clip_and_remove_zero_pixels(file_path,file_path,polygon_c)\n",
        "\n",
        "                      # main functionality on file path\n",
        "                      selected_bands=[2,3,4,8]\n",
        "                      with rasterio.open(file_path) as src:\n",
        "                          bands_data = src.read(selected_bands)\n",
        "                          width, height = src.width, src.height\n",
        "                          count = len(selected_bands)\n",
        "                          flat_data = bands_data.reshape((count, -1)).T\n",
        "                          column_names = [f'Band_{band}' for band in selected_bands]\n",
        "                          transform = src.transform\n",
        "                          srs = src.crs\n",
        "                          rows, cols = src.height, src.width\n",
        "                          y_coords, x_coords = [y for y in range(rows) for _ in range(cols)], [x for _ in range(rows) for x in range(cols)]\n",
        "                          pixel_coords = list(zip(y_coords, x_coords))\n",
        "                          lonlat_coords = [src.transform * (x, y) for y, x in pixel_coords]\n",
        "                          pixel_values_with_coords = [(lon, lat, *values) for (lon, lat), values in zip(lonlat_coords, flat_data)]\n",
        "                          column_names = ['Longitude', 'Latitude'] + column_names\n",
        "                          df = pd.DataFrame(pixel_values_with_coords, columns=column_names)\n",
        "\n",
        "                          for column in df.columns:\n",
        "                              df = df[df[column] != 0]\n",
        "\n",
        "                          # print(df.shape)\n",
        "                          df=df.reset_index()\n",
        "                          df=df.drop(columns={\"index\"})\n",
        "\n",
        "                          def ndvi(row):\n",
        "                              return (row['Band_8']-row['Band_4'])/(row['Band_8']+row['Band_4'])\n",
        "\n",
        "                          def gci(row):\n",
        "                              return (row['Band_8']-row['Band_3'])/(row['Band_8']+row['Band_3'])\n",
        "\n",
        "                          def lai(row):\n",
        "                              return (row['Band_8']-row['Band_4'])/((row['Band_8']+row['Band_4'])*2.5)\n",
        "\n",
        "                          def evi(row):\n",
        "                              gain_factor = 2.5\n",
        "                              offset = 1.0\n",
        "                              denominator=row['Band_8'] + 6 * row['Band_4'] - 7.5 * row['Band_2'] + offset\n",
        "\n",
        "                              if denominator==0:\n",
        "                                  evi=0\n",
        "                                  return evi\n",
        "                              else:\n",
        "                                  evi = gain_factor * (row['Band_8']-row['Band_4']) / (denominator)\n",
        "                                  return evi\n",
        "\n",
        "\n",
        "                          df['ndvi']=df.apply(ndvi,axis=1)\n",
        "                          df['gci']=df.apply(gci,axis=1)\n",
        "                          df['lai']=df.apply(lai,axis=1)\n",
        "                          df['evi']=df.apply(evi,axis=1)\n",
        "\n",
        "                          df.columns=[\"Longitude\",\"Latitude\",\"Band1\",\"Band2\",\"Band3\",\"Band4\",\"NDVI\",\"GCI\",\"LAI\",\"EVI\"]\n",
        "\n",
        "                          X=df.iloc[:,2:]\n",
        "\n",
        "                          X[np.isinf(X)] = np.finfo(np.float32).max\n",
        "                          X[np.isnan(X)] = 0\n",
        "\n",
        "                          scaler = StandardScaler()\n",
        "                          X_test = scaler.fit_transform(X)\n",
        "\n",
        "                          #load the model\n",
        "                          # classes - 0 - canopy cover , 1 - no canopy\n",
        "\n",
        "                          #predictions\n",
        "                          ann_sc = tf.keras.models.load_model(config_data_stand_count[\"sc_ml_model\"])\n",
        "\n",
        "                          # predictions\n",
        "                          predictions_ann=ann_sc.predict(X_test)\n",
        "                          argument=np.argmax(predictions_ann,axis=1)\n",
        "                          total_1=np.count_nonzero(argument==1)\n",
        "                          total_0=np.count_nonzero(argument==0)\n",
        "\n",
        "\n",
        "                          pixel_resolution=10*10\n",
        "                          total_pixel_counts=total_0+total_1\n",
        "                          total_area_m2=total_pixel_counts*pixel_resolution\n",
        "                          total_area_acres=total_area_m2/4046.86\n",
        "                          canopy_cover_area_m2=total_0*pixel_resolution\n",
        "                          canopy_cover_area_acres=canopy_cover_area_m2/4046.86\n",
        "\n",
        "                          #calculations\n",
        "\n",
        "                          def area_converter(A):\n",
        "                            b=str(A).split('.')\n",
        "                            num1=b[0]+'.'+b[1][:3]\n",
        "                            if float(b[1][1][:3]) < 5.0:\n",
        "                              num1=b[0]+'.'+b[1][:3]\n",
        "                              num1=float(num1)\n",
        "                              num1=np.round(num1,2)\n",
        "                              return num1\n",
        "                            else:\n",
        "                              num1=b[0]+'.'+b[1][:3]\n",
        "                              num2=num1[:num1.find(num1.replace(num1[-1],\" \"))]\n",
        "                              num2=num2.strip()\n",
        "                              num2=float(num2)\n",
        "                              return num2\n",
        "\n",
        "                          # back up -- >>\n",
        "                          # def restrict_round(c):\n",
        "                          #   c=str(c)\n",
        "                          #   b=c[c.find('.')-c.find('.'):c.find('.')+2]\n",
        "                          #   b=float(b)\n",
        "                          #   return b\n",
        "\n",
        "                          canopy_cover_area_acres=area_converter(canopy_cover_area_acres)\n",
        "                          stand_count=canopy_cover_area_m2/spacing\n",
        "                          stand_count=int(np.round(stand_count,2))\n",
        "\n",
        "                          plant_density=stand_count/canopy_cover_area_acres\n",
        "                          plant_density=float(np.round(plant_density,1))\n",
        "\n",
        "                          recommended_plants=total_area_m2/spacing\n",
        "                          recommended_plants=int(np.round(recommended_plants))\n",
        "\n",
        "                          planned_seedling_density= recommended_plants/canopy_cover_area_acres\n",
        "                          planned_seedling_density=float(np.round(planned_seedling_density,1))\n",
        "\n",
        "                          recommended_plants=int(np.round(recommended_plants))\n",
        "                          stand_count=int(np.round(stand_count))\n",
        "\n",
        "\n",
        "                          difference=recommended_plants-stand_count\n",
        "                          under_norm=difference/recommended_plants\n",
        "                          under_norm=area_converter(under_norm)*100\n",
        "\n",
        "                          #bar chart\n",
        "                          labels = ['Recommended7 Plants', 'Stand Count']\n",
        "                          values = [recommended_plants, stand_count]\n",
        "                          colors = ['green', 'blue']\n",
        "                          # plt.figure(figsize=(7,5))\n",
        "                          # ax = sns.barplot(x=labels, y=values, palette=colors)\n",
        "                          # plt.title('Stand Cout Analysis')\n",
        "                          # plt.yticks([])\n",
        "                          # for i, value in enumerate(values):\n",
        "                          #     ax.text(i, value + 0.5, f'{value:,}', ha='center', va='bottom')\n",
        "                          # plt.savefig(f\"output/potato_stand_count/stand_count_bar_chart_{save_date}.jpg\")\n",
        "                          # plt.close()\n",
        "\n",
        "                          # creating the map\n",
        "                          pred_df= pd.DataFrame(argument,columns=['pred'])\n",
        "                          df_lat_long=pd.concat([df['Longitude'],df['Latitude'],pred_df['pred']],axis=1)\n",
        "                          geometry = [Point(xy) for xy in zip(df_lat_long ['Longitude'], df_lat_long ['Latitude'])]\n",
        "                          gdf = gpd.GeoDataFrame(df_lat_long , crs=\"EPSG:4326\", geometry=geometry)\n",
        "                          # print(gdf)\n",
        "                          colors = {0: 'orange', 1: 'purple'}\n",
        "                          labels={'Plants':'orange','No Plants':'purple'}\n",
        "                          ax = gdf.plot(color=[colors[val] for val in gdf['pred']], legend=True)\n",
        "\n",
        "                          plt.title('Stand Count Map')\n",
        "                          ax.set_xlabel('')\n",
        "                          ax.set_ylabel('')\n",
        "                          ax.set_xticks([])\n",
        "                          ax.set_yticks([])\n",
        "\n",
        "                          handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=15, label=label) for label, color in labels.items()]\n",
        "                          ax.legend(handles=handles, title='Legend', title_fontsize='large', loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=2)\n",
        "\n",
        "                          fig = plt.gcf()\n",
        "                          fig.set_size_inches(6, 6)\n",
        "                          map_rel_path=cc_output_directory+\"/stand_count_map_\"\n",
        "                          map_path = f\"{map_rel_path}{save_date}.jpg\"\n",
        "                          plt.savefig(map_path,dpi=500)\n",
        "                          plt.close()\n",
        "\n",
        "                          #json file path\n",
        "                          output_rel_path=cc_output_directory+\"/stand_count_output_\"\n",
        "                          canopy_cover_output_json_path=f\"{output_rel_path}{save_date}.json\"\n",
        "\n",
        "                          # date conversion dd-mm-yy\n",
        "                          # analysis_date=datetime.strptime(analysis_date,'%Y-%m-%d').strftime('%d-%m-%Y')\n",
        "                          sowing_date=datetime.strptime(sowing_date,'%Y-%m-%d').strftime('%d-%m-%Y')\n",
        "                          all_data={\n",
        "                                      \"reportFor\":\"plant_stand_count\",\n",
        "                                      \"name\": org_name,\n",
        "                                      \"crop_name\": crop_name,\n",
        "                                      \"service Name\": service_name,\n",
        "                                      \"analysis_date\": analysis_date,\n",
        "                                      \"sowing_date\": sowing_date,\n",
        "                                      \"crop_area\": area_converter(total_area_acres),\n",
        "                                      \"PLANTS COUNTED\": stand_count,\n",
        "                                      \"PLANT DENSITY PER ACRE\": plant_density,\n",
        "                                      \"PLANNED SEEDLING DENSITY PER ACRE\": planned_seedling_density,\n",
        "                                      \"plants in percentages\": f\"{under_norm}%\",\n",
        "                                      \"The total Plants under the norm is\": difference,\n",
        "                                      \"bar\":[{\n",
        "                                      \"rowKey\":\"Recomended Plant\",\n",
        "                                      \"rowvalue\":recommended_plants\n",
        "                                      },{\n",
        "                                      \"rowKey\":\"Stand Plant\",\n",
        "                                      \"rowvalue\":stand_count\n",
        "                                      }],\n",
        "                                      \"map\":f\"stand_count_map_{save_date}.jpg\"\n",
        "                          }\n",
        "\n",
        "\n",
        "                      with open(canopy_cover_output_json_path, 'w') as json_file:\n",
        "                          json.dump(all_data, json_file, indent=4)\n",
        "\n",
        "                      # cleared the tiff file from folder\n",
        "                      def clear_directory(directory_path):\n",
        "                          shutil.rmtree(directory_path, ignore_errors=True)\n",
        "                          os.makedirs(directory_path)\n",
        "\n",
        "                      directory_path_to_clear=config_data_main[\"data_output_folder\"]\n",
        "                      clear_directory(directory_path_to_clear)\n",
        "\n",
        "                      return canopy_cover_output_json_path\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error reading TIFF file: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main processing ErroR Might be due to Satellite image or directory in which image is getting stored : {e}\")\n",
        "\n",
        "\n",
        "def main(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing):\n",
        "\n",
        "  try:\n",
        "\n",
        "    # org_name ='abc'\n",
        "    # crop_name=data['crop_name']\n",
        "    # sowing_date=data['showing_date']\n",
        "    # service_name=data['service_name']\n",
        "    # analysis_date=data['analysis_date']\n",
        "    # polygon_c=data['geom']\n",
        "    # input_spacing=data['spacing']\n",
        "    stand_count_output=standcount(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing)\n",
        "    print(stand_count_output)\n",
        "\n",
        "  except:\n",
        "      print(\"Service Unavailable at this moment\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    input_spacing=\"0.15*0.20\"\n",
        "    analysis_date = \"2023-12-25\"\n",
        "    polygon_c=[[73.09556979663124, 23.8405276975719],\n",
        "            [73.10241918097321, 23.84029256809925],\n",
        "            [73.10268407569515, 23.83403065470798],\n",
        "            [73.0957683354565, 23.83407320230542],\n",
        "            [73.09556979663124, 23.8405276975719]]\n",
        "    org_name='abc'\n",
        "    crop_name=\"potato\"\n",
        "    sowing_date='2023-12-18'\n",
        "    service_name='Stand Count'\n",
        "    # data = json.loads(sys.argv[1])\n",
        "    try:\n",
        "        main(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing)\n",
        "    except:\n",
        "        print(\"internal error\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "ViPeJPO8EjYn",
        "outputId": "0b535a50-3b58-43e2-9ae7-1c5e472b93a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'memory_profiler'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1847156beaec>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmemory_profiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrio_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'memory_profiler'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentinelhub\n",
        "!pip install rasterio\n",
        "!pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIZLhrh-shJU",
        "outputId": "a12e76ea-524b-4316-b3d9-b51fdeb5f4a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentinelhub\n",
            "  Downloading sentinelhub-3.10.1-py3-none-any.whl (245 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.4/245.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=2.1.4 (from sentinelhub)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (8.1.7)\n",
            "Collecting dataclasses-json (from sentinelhub)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (1.25.2)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (3.2.2)\n",
            "Requirement already satisfied: pillow>=9.2.0 in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (9.4.0)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (3.6.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (2.8.2)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (1.3.1)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (2.31.0)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (2.0.4)\n",
            "Requirement already satisfied: tifffile>=2020.9.30 in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (2024.2.12)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (2.0.1)\n",
            "Collecting tomli-w (from sentinelhub)\n",
            "  Downloading tomli_w-1.0.0-py3-none-any.whl (6.0 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from sentinelhub) (4.11.0)\n",
            "Collecting utm (from sentinelhub)\n",
            "  Downloading utm-0.7.0.tar.gz (8.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=2.2.0->sentinelhub) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->sentinelhub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->sentinelhub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->sentinelhub) (2.0.7)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->sentinelhub)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json->sentinelhub)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->sentinelhub) (1.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->sentinelhub) (24.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->sentinelhub)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: utm\n",
            "  Building wheel for utm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utm: filename=utm-0.7.0-py3-none-any.whl size=6084 sha256=75c6c9322da0b19b2efe9b750886ceba7668329bd34c84f968c8cd2c9b2cce62\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/a1/c8/543df0e8f5e824c3e92a432e32deb9cd89ae686095ee8cfcbe\n",
            "Successfully built utm\n",
            "Installing collected packages: utm, aenum, tomli-w, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, sentinelhub\n",
            "Successfully installed aenum-3.1.15 dataclasses-json-0.6.4 marshmallow-3.21.1 mypy-extensions-1.0.0 sentinelhub-3.10.1 tomli-w-1.0.0 typing-inspect-0.9.0 utm-0.7.0\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.10-cp310-cp310-manylinux2014_x86_64.whl (21.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.2.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.10 snuggs-1.4.7\n",
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDSmr-2FpFX5",
        "outputId": "2fc916ea-8765-4e32-cb87-b881d06b2223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Stand Count Analysis --optimized\n",
        "\n",
        "# Libraries\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sentinelhub\n",
        "from sentinelhub import SHConfig\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "from matplotlib.colors import PowerNorm\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import json\n",
        "# import base64\n",
        "# from io import BytesIO\n",
        "import rasterio\n",
        "from rasterio.mask import mask as rio_mask\n",
        "from shapely.geometry import Point,Polygon\n",
        "from osgeo import gdal\n",
        "import shutil\n",
        "from sentinelhub import (\n",
        "        CRS,\n",
        "        BBox,\n",
        "        DataCollection,\n",
        "        DownloadRequest,\n",
        "        MimeType,\n",
        "        MosaickingOrder,\n",
        "        SentinelHubDownloadClient,\n",
        "        SentinelHubRequest,\n",
        "        bbox_to_dimensions,\n",
        ")\n",
        "\n",
        "#extracting the date\n",
        "def extract_start_date(analysis_date):\n",
        "    e=datetime.strptime(analysis_date,'%Y-%m-%d')\n",
        "    s=e-timedelta(7)\n",
        "    start_date=s.strftime('%Y-%m-%d')\n",
        "    return start_date\n",
        "\n",
        "# clip the image from shapefile\n",
        "def clip_and_remove_zero_pixels(file_a,path_b,polygon_c,file_path_temp):\n",
        "    with rasterio.open(file_a) as src:\n",
        "        polygon = Polygon(polygon_c)\n",
        "\n",
        "        out_image, out_transform = rio_mask(src, [polygon], crop=True)\n",
        "\n",
        "        out_meta = src.meta.copy()\n",
        "        out_meta.update({\"driver\": \"GTiff\",\n",
        "                        \"height\": out_image.shape[1],\n",
        "                        \"width\": out_image.shape[2],\n",
        "                        \"transform\": out_transform})\n",
        "\n",
        "    clipped_raster_path = file_path_temp + \"file.tiff\"\n",
        "    with rasterio.open(clipped_raster_path, \"w\", **out_meta) as dest:\n",
        "        dest.write(out_image)\n",
        "\n",
        "    src_ds = gdal.Open(clipped_raster_path)\n",
        "    if src_ds is None:\n",
        "        print(\"Failed to open the clipped raster file.\")\n",
        "        return\n",
        "\n",
        "    cols = src_ds.RasterXSize\n",
        "    rows = src_ds.RasterYSize\n",
        "    bands = src_ds.RasterCount\n",
        "\n",
        "    driver = gdal.GetDriverByName(\"GTiff\")\n",
        "    dst_ds = driver.Create(path_b, cols, rows, bands, gdal.GDT_Float32)\n",
        "\n",
        "    dst_ds.SetProjection(src_ds.GetProjection())\n",
        "    dst_ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
        "\n",
        "    for band_idx in range(1, bands + 1):\n",
        "        band = src_ds.GetRasterBand(band_idx)\n",
        "        band_array = band.ReadAsArray()\n",
        "\n",
        "        mask_array = (band_array == -99999)\n",
        "\n",
        "        masked_band_array = np.where(mask_array, np.nan, band_array)\n",
        "\n",
        "        dst_band = dst_ds.GetRasterBand(band_idx)\n",
        "        dst_band.WriteArray(masked_band_array)\n",
        "\n",
        "    src_ds = None\n",
        "    dst_ds = None\n",
        "\n",
        "    os.remove(clipped_raster_path)\n",
        "\n",
        "# feature creation\n",
        "def ndvi(row):\n",
        "    return (row['Band_8']-row['Band_4'])/(row['Band_8']+row['Band_4'])\n",
        "\n",
        "def gci(row):\n",
        "    return (row['Band_8']-row['Band_3'])/(row['Band_8']+row['Band_3'])\n",
        "\n",
        "def lai(row):\n",
        "    return (row['Band_8']-row['Band_4'])/((row['Band_8']+row['Band_4'])*2.5)\n",
        "\n",
        "def evi(row):\n",
        "    gain_factor = 2.5\n",
        "    offset = 1.0\n",
        "    denominator=row['Band_8'] + 6 * row['Band_4'] - 7.5 * row['Band_2'] + offset\n",
        "\n",
        "    if denominator==0:\n",
        "        evi=0\n",
        "        return evi\n",
        "    else:\n",
        "        evi = gain_factor * (row['Band_8']-row['Band_4']) / (denominator)\n",
        "        return evi\n",
        "\n",
        "# area conversion\n",
        "def area_converter(A):\n",
        "  b=str(A).split('.')\n",
        "  num1=b[0]+'.'+b[1][:3]\n",
        "  if float(b[1][1][:3]) < 5.0:\n",
        "    num1=b[0]+'.'+b[1][:3]\n",
        "    num1=float(num1)\n",
        "    num1=np.round(num1,2)\n",
        "    return num1\n",
        "  else:\n",
        "    num1=b[0]+'.'+b[1][:3]\n",
        "    num2=num1[:num1.find(num1.replace(num1[-1],\" \"))]\n",
        "    num2=num2.strip()\n",
        "    num2=float(num2)\n",
        "    return num2\n",
        "\n",
        "# clear the directory\n",
        "def clear_directory(directory_path):\n",
        "    shutil.rmtree(directory_path, ignore_errors=True)\n",
        "    os.makedirs(directory_path)\n",
        "\n",
        "def standcount(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing):\n",
        "\n",
        "    with open('/content/drive/MyDrive/internship/B - with GDAL/python_services_config.json','r') as config_file:\n",
        "        get_configuration = json.load(config_file)\n",
        "\n",
        "    config_data_stand_count=get_configuration['potato_stand_count']\n",
        "    config_data_main=get_configuration['main']\n",
        "\n",
        "    config = SHConfig()\n",
        "\n",
        "    config.sh_client_id = config_data_main[\"sh_client_id\"]\n",
        "    config.sh_client_secret = config_data_main[\"sh_client_secret\"]\n",
        "    config.save()\n",
        "\n",
        "    today=datetime.now()\n",
        "    save_date=today.strftime(\"%Y-%m-%d-%H-%m-%s\")\n",
        "\n",
        "    home_directory = os.path.expanduser(\"~\")\n",
        "    cc_output_directory = os.path.join(home_directory,config_data_stand_count['output_folder'])\n",
        "    os.makedirs(cc_output_directory, exist_ok=True)\n",
        "\n",
        "    start_date=extract_start_date(analysis_date)\n",
        "    end_date=analysis_date\n",
        "\n",
        "    # extract the spacing format 25*26m2\n",
        "    number=input_spacing.split(\"*\")\n",
        "    num1=float(number[0])\n",
        "    num2=float(number[1])\n",
        "    spacing=num1+num2\n",
        "\n",
        "    # boudning box\n",
        "    min_x = min(p[0] for p in polygon_c)\n",
        "    max_x = max(p[0] for p in polygon_c)\n",
        "    min_y = min(p[1] for p in polygon_c)\n",
        "    max_y = max(p[1] for p in polygon_c)\n",
        "\n",
        "\n",
        "    bounding_box = (min_x, min_y, max_x, max_y)\n",
        "    resolution = 10\n",
        "    betsiboka_bbox = BBox(bbox=bounding_box, crs=CRS.WGS84)\n",
        "    betsiboka_size = bbox_to_dimensions(betsiboka_bbox, resolution=resolution)\n",
        "\n",
        "    # print(f\"Image shape at {resolution} m resolution: {betsiboka_size} pixels\")\n",
        "\n",
        "    evalscript_all_bands = \"\"\"\n",
        "        //VERSION=3\n",
        "        function setup() {\n",
        "            return {\n",
        "                input: [{\n",
        "                    bands: [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"],\n",
        "                    units: \"DN\"\n",
        "                }],\n",
        "                output: {\n",
        "                    bands: 13,\n",
        "                    sampleType: \"INT16\"\n",
        "                }\n",
        "            };\n",
        "        }\n",
        "\n",
        "        function evaluatePixel(sample) {\n",
        "            return [sample.B01,\n",
        "                    sample.B02,\n",
        "                    sample.B03,\n",
        "                    sample.B04,\n",
        "                    sample.B05,\n",
        "                    sample.B06,\n",
        "                    sample.B07,\n",
        "                    sample.B08,\n",
        "                    sample.B8A,\n",
        "                    sample.B09,\n",
        "                    sample.B10,\n",
        "                    sample.B11,\n",
        "                    sample.B12];\n",
        "        }\n",
        "    \"\"\"\n",
        "\n",
        "    request_all_bands = SentinelHubRequest(\n",
        "        evalscript=evalscript_all_bands,\n",
        "        data_folder=config_data_main[\"data_output_folder\"],\n",
        "        input_data=[\n",
        "            SentinelHubRequest.input_data(\n",
        "                data_collection=DataCollection.SENTINEL2_L1C,\n",
        "                time_interval=(str(start_date),str(end_date)),\n",
        "                mosaicking_order=MosaickingOrder.LEAST_CC,\n",
        "            )\n",
        "        ],\n",
        "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
        "        bbox=betsiboka_bbox,\n",
        "        size=betsiboka_size,\n",
        "        config=config,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "\n",
        "        all_bands_response = request_all_bands.get_data()\n",
        "\n",
        "        # stacked image\n",
        "        # %%time\n",
        "        all_bands_img = request_all_bands.get_data(save_data=True)\n",
        "\n",
        "        for folder, _, filenames in os.walk(request_all_bands.data_folder):\n",
        "            for filename in filenames:\n",
        "                file_path = os.path.join(folder, filename)\n",
        "\n",
        "                if filename.endswith(\".tif\") or filename.endswith(\".tiff\"):\n",
        "\n",
        "                    try:\n",
        "                      clip_and_remove_zero_pixels(file_path,file_path,polygon_c,config_data_main[\"data_output_folder\"])\n",
        "\n",
        "                      # main functionality on file path\n",
        "                      selected_bands=[2,3,4,8]\n",
        "                      with rasterio.open(file_path) as src:\n",
        "                          bands_data = src.read(selected_bands)\n",
        "                          width, height = src.width, src.height\n",
        "                          count = len(selected_bands)\n",
        "                          flat_data = bands_data.reshape((count, -1)).T\n",
        "                          column_names = ['Band_{}'.format(band) for band in selected_bands]\n",
        "                          transform = src.transform\n",
        "                          srs = src.crs\n",
        "                          rows, cols = src.height, src.width\n",
        "                          y_coords, x_coords = [y for y in range(rows) for _ in range(cols)], [x for _ in range(rows) for x in range(cols)]\n",
        "                          pixel_coords = list(zip(y_coords, x_coords))\n",
        "                          lonlat_coords = [src.transform * (x, y) for y, x in pixel_coords]\n",
        "                          pixel_values_with_coords = [(lon, lat, *values) for (lon, lat), values in zip(lonlat_coords, flat_data)]\n",
        "                          column_names = ['Longitude', 'Latitude'] + column_names\n",
        "                          df = pd.DataFrame(pixel_values_with_coords, columns=column_names)\n",
        "\n",
        "                          for column in df.columns:\n",
        "                              df = df[df[column] != 0]\n",
        "\n",
        "                          # print(df.shape)\n",
        "                          df=df.reset_index()\n",
        "                          df=df.drop(columns={\"index\"})\n",
        "\n",
        "                          def ndvi(row):\n",
        "                              return (row['Band_8']-row['Band_4'])/(row['Band_8']+row['Band_4'])\n",
        "\n",
        "                          def gci(row):\n",
        "                              return (row['Band_8']-row['Band_3'])/(row['Band_8']+row['Band_3'])\n",
        "\n",
        "                          def lai(row):\n",
        "                              return (row['Band_8']-row['Band_4'])/((row['Band_8']+row['Band_4'])*2.5)\n",
        "\n",
        "                          def evi(row):\n",
        "                              gain_factor = 2.5\n",
        "                              offset = 1.0\n",
        "                              denominator=row['Band_8'] + 6 * row['Band_4'] - 7.5 * row['Band_2'] + offset\n",
        "\n",
        "                              if denominator==0:\n",
        "                                  evi=0\n",
        "                                  return evi\n",
        "                              else:\n",
        "                                  evi = gain_factor * (row['Band_8']-row['Band_4']) / (denominator)\n",
        "                                  return evi\n",
        "\n",
        "\n",
        "                          df['ndvi']=df.apply(ndvi,axis=1)\n",
        "                          df['gci']=df.apply(gci,axis=1)\n",
        "                          df['lai']=df.apply(lai,axis=1)\n",
        "                          df['evi']=df.apply(evi,axis=1)\n",
        "\n",
        "                          df.columns=[\"Longitude\",\"Latitude\",\"Band1\",\"Band2\",\"Band3\",\"Band4\",\"NDVI\",\"GCI\",\"LAI\",\"EVI\"]\n",
        "\n",
        "                          X=df.iloc[:,2:]\n",
        "\n",
        "                          X[np.isinf(X)] = np.finfo(np.float32).max\n",
        "                          X[np.isnan(X)] = 0\n",
        "\n",
        "                          scaler = StandardScaler()\n",
        "                          X_test = scaler.fit_transform(X)\n",
        "\n",
        "                          #load the model\n",
        "                          # classes - 0 - canopy cover , 1 - no canopy\n",
        "\n",
        "                          #predictions\n",
        "                          ann_sc = tf.keras.models.load_model(config_data_stand_count[\"sc_ml_model\"])\n",
        "\n",
        "                          # predictions\n",
        "                          predictions_ann=ann_sc.predict(X_test)\n",
        "                          argument=np.argmax(predictions_ann,axis=1)\n",
        "                          total_1=np.count_nonzero(argument==1)\n",
        "                          total_0=np.count_nonzero(argument==0)\n",
        "\n",
        "\n",
        "                          pixel_resolution=10*10\n",
        "                          total_pixel_counts=total_0+total_1\n",
        "                          total_area_m2=total_pixel_counts*pixel_resolution\n",
        "                          total_area_acres=total_area_m2/4046.86\n",
        "                          canopy_cover_area_m2=total_0*pixel_resolution\n",
        "                          canopy_cover_area_acres=canopy_cover_area_m2/4046.86\n",
        "\n",
        "                          #calculations\n",
        "\n",
        "\n",
        "\n",
        "                          # back up -- >>\n",
        "                          # def restrict_round(c):\n",
        "                          #   c=str(c)\n",
        "                          #   b=c[c.find('.')-c.find('.'):c.find('.')+2]\n",
        "                          #   b=float(b)\n",
        "                          #   return b\n",
        "\n",
        "                          canopy_cover_area_acres=area_converter(canopy_cover_area_acres)\n",
        "                          stand_count=canopy_cover_area_m2/spacing\n",
        "                          stand_count=int(np.round(stand_count,2))\n",
        "\n",
        "                          plant_density=stand_count/canopy_cover_area_acres\n",
        "                          plant_density=float(np.round(plant_density,1))\n",
        "\n",
        "                          recommended_plants=total_area_m2/spacing\n",
        "                          recommended_plants=int(np.round(recommended_plants))\n",
        "\n",
        "                          planned_seedling_density= recommended_plants/canopy_cover_area_acres\n",
        "                          planned_seedling_density=float(np.round(planned_seedling_density,1))\n",
        "\n",
        "                          recommended_plants=int(np.round(recommended_plants))\n",
        "                          stand_count=int(np.round(stand_count))\n",
        "\n",
        "\n",
        "                          difference=recommended_plants-stand_count\n",
        "                          under_norm=difference/recommended_plants\n",
        "                          under_norm=area_converter(under_norm)*100\n",
        "\n",
        "                          #bar chart\n",
        "                          labels = ['Recommended7 Plants', 'Stand Count']\n",
        "                          values = [recommended_plants, stand_count]\n",
        "                          colors = ['green', 'blue']\n",
        "                          # plt.figure(figsize=(7,5))\n",
        "                          # ax = sns.barplot(x=labels, y=values, palette=colors)\n",
        "                          # plt.title('Stand Cout Analysis')\n",
        "                          # plt.yticks([])\n",
        "                          # for i, value in enumerate(values):\n",
        "                          #     ax.text(i, value + 0.5, f'{value:,}', ha='center', va='bottom')\n",
        "                          # plt.savefig(f\"output/potato_stand_count/stand_count_bar_chart_{save_date}.jpg\")\n",
        "                          # plt.close()\n",
        "\n",
        "                          # creating the map\n",
        "                          pred_df= pd.DataFrame(argument,columns=['pred'])\n",
        "                          df_lat_long=pd.concat([df['Longitude'],df['Latitude'],pred_df['pred']],axis=1)\n",
        "                          geometry = [Point(xy) for xy in zip(df_lat_long ['Longitude'], df_lat_long ['Latitude'])]\n",
        "                          gdf = gpd.GeoDataFrame(df_lat_long , crs=\"EPSG:4326\", geometry=geometry)\n",
        "                          # print(gdf)\n",
        "                          colors = {0: 'orange', 1: 'purple'}\n",
        "                          labels={'Plants':'orange','No Plants':'purple'}\n",
        "                          ax = gdf.plot(color=[colors[val] for val in gdf['pred']], legend=True, marker='s', markersize=180)\n",
        "\n",
        "                          plt.title('Stand Count Map')\n",
        "                          ax.set_xlabel('')\n",
        "                          ax.set_ylabel('')\n",
        "                          ax.set_xticks([])\n",
        "                          ax.set_yticks([])\n",
        "\n",
        "                          handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=15, label=label) for label, color in labels.items()]\n",
        "                          ax.legend(handles=handles, title='Legend', title_fontsize='large', loc='upper center', bbox_to_anchor=(0.5, -0.01), fancybox=True, shadow=True, ncol=2)\n",
        "\n",
        "                          fig = plt.gcf()\n",
        "                          fig.set_size_inches(6, 6)\n",
        "                          map_rel_path=cc_output_directory+\"/stand_count_map_\"\n",
        "                          map_path = \"{}{}.jpg\".format(map_rel_path,save_date)\n",
        "                          plt.savefig(map_path,dpi=500)\n",
        "                          plt.close()\n",
        "\n",
        "                          #json file path\n",
        "                          output_rel_path=cc_output_directory+\"/stand_count_output_\"\n",
        "                          stand_count_output_json_path=\"{}{}.json\".format(output_rel_path,save_date)\n",
        "\n",
        "                          # date conversion dd-mm-yy\n",
        "                          # analysis_date=datetime.strptime(analysis_date,'%Y-%m-%d').strftime('%d-%m-%Y')\n",
        "                          sowing_date=datetime.strptime(sowing_date,'%Y-%m-%d').strftime('%d-%m-%Y')\n",
        "                          all_data={\n",
        "                                      \"reportFor\":\"plant_stand_count\",\n",
        "                                      \"name\": org_name,\n",
        "                                      \"crop_name\": crop_name,\n",
        "                                      \"service Name\": service_name,\n",
        "                                      \"analysis_date\": analysis_date,\n",
        "                                      \"sowing_date\": sowing_date,\n",
        "                                      \"crop_area\": area_converter(total_area_acres),\n",
        "                                      \"PLANTS COUNTED\": stand_count,\n",
        "                                      \"PLANT DENSITY PER ACRE\": plant_density,\n",
        "                                      \"PLANNED SEEDLING DENSITY PER ACRE\": planned_seedling_density,\n",
        "                                      \"plants in percentages\": \"{}%\".format(under_norm),\n",
        "                                      \"The total Plants under the norm is\": difference,\n",
        "                                      \"bar\":[{\n",
        "                                      \"rowKey\":\"Recomended Plant\",\n",
        "                                      \"rowvalue\":recommended_plants\n",
        "                                      },{\n",
        "                                      \"rowKey\":\"Stand Plant\",\n",
        "                                      \"rowvalue\":stand_count\n",
        "                                      }],\n",
        "                                      \"map\":\"{}{}{}.jpg\".format('stand_count','/stand_count_map_',save_date)\n",
        "                          }\n",
        "\n",
        "\n",
        "                      with open(stand_count_output_json_path, 'w') as json_file:\n",
        "                          json.dump(all_data, json_file, indent=4)\n",
        "\n",
        "                      # cleared the tiff file from folder\n",
        "                      def clear_directory(directory_path):\n",
        "                          shutil.rmtree(directory_path, ignore_errors=True)\n",
        "                          os.makedirs(directory_path)\n",
        "\n",
        "                      directory_path_to_clear=config_data_main[\"data_output_folder\"]\n",
        "                      clear_directory(directory_path_to_clear)\n",
        "\n",
        "                      return stand_count_output_json_path\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(\"Error reading TIFF file: {}\".format(e))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error in main processing ErroR Might be due to Satellite image or directory in which image is getting stored : {}\".format(e))\n",
        "\n",
        "\n",
        "def main(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing):\n",
        "\n",
        "  try:\n",
        "\n",
        "    # org_name ='abc'\n",
        "    # crop_name=data['crop_name']\n",
        "    # sowing_date=data['showing_date']\n",
        "    # service_name=data['service_name']\n",
        "    # analysis_date=data['analysis_date']\n",
        "    # polygon_c=data['geom']\n",
        "    # input_spacing=data['spacing']\n",
        "    stand_count_output=standcount(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing)\n",
        "    print(stand_count_output)\n",
        "\n",
        "  except:\n",
        "      print(\"Service Unavailable at this moment\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    input_spacing=\"0.15*0.20\"\n",
        "    analysis_date = \"2023-12-25\"\n",
        "    polygon_c=[[73.09556979663124, 23.8405276975719],\n",
        "            [73.10241918097321, 23.84029256809925],\n",
        "            [73.10268407569515, 23.83403065470798],\n",
        "            [73.0957683354565, 23.83407320230542],\n",
        "            [73.09556979663124, 23.8405276975719]]\n",
        "    org_name='abc'\n",
        "    crop_name=\"potato\"\n",
        "    sowing_date='2023-12-18'\n",
        "    service_name='Stand Count'\n",
        "    # data = json.loads(sys.argv[1])\n",
        "    try:\n",
        "        %load_ext memory_profiler\n",
        "        # %memit -r 1\n",
        "        %memit -r 1 main(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing)\n",
        "    except:\n",
        "        print(\"internal error\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6bMZrwDpGRY",
        "outputId": "2042487e-7fea-4974-a559-75d16d3511ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "WARNING:rasterio._env:CPLE_AppDefined in temp_dir/e11ebaa7204e2b9d0103ea60e541e020/response.tiff: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
            "WARNING:rasterio._env:CPLE_AppDefined in TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154/154 [==============================] - 0s 2ms/step\n",
            "/root/agri_crop/image/potato/stand_count/stand_count_output_2024-04-14-04-04-1713068175.json\n",
            "peak memory: 895.26 MiB, increment: 66.17 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Stand Count Analysis\n",
        "\n",
        "# Libraries\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sentinelhub\n",
        "from sentinelhub import SHConfig\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "from matplotlib.colors import PowerNorm\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import json\n",
        "import memory_profiler\n",
        "import rasterio\n",
        "from rasterio.mask import mask as rio_mask\n",
        "from shapely.geometry import Point,Polygon\n",
        "from osgeo import gdal\n",
        "import shutil\n",
        "from sentinelhub import (\n",
        "        CRS,\n",
        "        BBox,\n",
        "        DataCollection,\n",
        "        DownloadRequest,\n",
        "        MimeType,\n",
        "        MosaickingOrder,\n",
        "        SentinelHubDownloadClient,\n",
        "        SentinelHubRequest,\n",
        "        bbox_to_dimensions,\n",
        ")\n",
        "\n",
        "\n",
        "def standcount(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing):\n",
        "\n",
        "    with open('/content/drive/MyDrive/internship/B - with GDAL/python_services_config.json','r') as config_file:\n",
        "        get_configuration = json.load(config_file)\n",
        "\n",
        "    config_data_stand_count=get_configuration['potato_stand_count']\n",
        "    config_data_main=get_configuration['main']\n",
        "\n",
        "    config = SHConfig()\n",
        "\n",
        "    config.sh_client_id = config_data_main[\"sh_client_id\"]\n",
        "    config.sh_client_secret = config_data_main[\"sh_client_secret\"]\n",
        "    config.save()\n",
        "\n",
        "    today=datetime.now()\n",
        "    save_date=today.strftime(\"%Y-%m-%d-%H-%m-%s\")\n",
        "\n",
        "    home_directory = os.path.expanduser(\"~\")\n",
        "    cc_output_directory = os.path.join(home_directory,config_data_stand_count['output_folder'])\n",
        "    os.makedirs(cc_output_directory, exist_ok=True)\n",
        "\n",
        "    # date\n",
        "    def extract_start_date(analysis_date):\n",
        "        e=datetime.strptime(analysis_date,'%Y-%m-%d')\n",
        "        s=e-timedelta(7)\n",
        "        start_date=s.strftime('%Y-%m-%d')\n",
        "        return start_date\n",
        "\n",
        "    start_date=extract_start_date(analysis_date)\n",
        "    end_date=analysis_date\n",
        "\n",
        "    # extract the spacing format 25*26m2\n",
        "    number=input_spacing.split(\"*\")\n",
        "    num1=float(number[0])\n",
        "    num2=float(number[1])\n",
        "    spacing=num1+num2\n",
        "\n",
        "    # boudning box\n",
        "    min_x = min(p[0] for p in polygon_c)\n",
        "    max_x = max(p[0] for p in polygon_c)\n",
        "    min_y = min(p[1] for p in polygon_c)\n",
        "    max_y = max(p[1] for p in polygon_c)\n",
        "\n",
        "\n",
        "    bounding_box = (min_x, min_y, max_x, max_y)\n",
        "    resolution = 10\n",
        "    betsiboka_bbox = BBox(bbox=bounding_box, crs=CRS.WGS84)\n",
        "    betsiboka_size = bbox_to_dimensions(betsiboka_bbox, resolution=resolution)\n",
        "\n",
        "    # print(f\"Image shape at {resolution} m resolution: {betsiboka_size} pixels\")\n",
        "\n",
        "    evalscript_all_bands = \"\"\"\n",
        "        //VERSION=3\n",
        "        function setup() {\n",
        "            return {\n",
        "                input: [{\n",
        "                    bands: [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"],\n",
        "                    units: \"DN\"\n",
        "                }],\n",
        "                output: {\n",
        "                    bands: 13,\n",
        "                    sampleType: \"INT16\"\n",
        "                }\n",
        "            };\n",
        "        }\n",
        "\n",
        "        function evaluatePixel(sample) {\n",
        "            return [sample.B01,\n",
        "                    sample.B02,\n",
        "                    sample.B03,\n",
        "                    sample.B04,\n",
        "                    sample.B05,\n",
        "                    sample.B06,\n",
        "                    sample.B07,\n",
        "                    sample.B08,\n",
        "                    sample.B8A,\n",
        "                    sample.B09,\n",
        "                    sample.B10,\n",
        "                    sample.B11,\n",
        "                    sample.B12];\n",
        "        }\n",
        "    \"\"\"\n",
        "\n",
        "    request_all_bands = SentinelHubRequest(\n",
        "        evalscript=evalscript_all_bands,\n",
        "        data_folder=config_data_main[\"data_output_folder\"],\n",
        "        input_data=[\n",
        "            SentinelHubRequest.input_data(\n",
        "                data_collection=DataCollection.SENTINEL2_L1C,\n",
        "                time_interval=(str(start_date),str(end_date)),\n",
        "                mosaicking_order=MosaickingOrder.LEAST_CC,\n",
        "            )\n",
        "        ],\n",
        "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
        "        bbox=betsiboka_bbox,\n",
        "        size=betsiboka_size,\n",
        "        config=config,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "\n",
        "        all_bands_response = request_all_bands.get_data()\n",
        "\n",
        "        # stacked image\n",
        "        # %%time\n",
        "        all_bands_img = request_all_bands.get_data(save_data=True)\n",
        "\n",
        "        for folder, _, filenames in os.walk(request_all_bands.data_folder):\n",
        "            for filename in filenames:\n",
        "                file_path = os.path.join(folder, filename)\n",
        "\n",
        "                if filename.endswith(\".tif\") or filename.endswith(\".tiff\"):\n",
        "\n",
        "                    try:\n",
        "                      # clip the raster for getting the image with nan pixels\n",
        "                      selected_bands=[2,3,4,8]\n",
        "                      def clip_and_remove_zero_pixels(file_a,path_b,polygon_c):\n",
        "                          with rasterio.open(file_a) as src:\n",
        "                              polygon = Polygon(polygon_c)\n",
        "\n",
        "                              out_image, out_transform = rio_mask(src, [polygon], crop=True)\n",
        "\n",
        "                              out_meta = src.meta.copy()\n",
        "                              out_meta.update({\"driver\": \"GTiff\",\n",
        "                                              \"height\": out_image.shape[1],\n",
        "                                              \"width\": out_image.shape[2],\n",
        "                                              \"transform\": out_transform})\n",
        "\n",
        "                          clipped_raster_path = config_data_main[\"data_output_folder\"]+\"file.tiff\"\n",
        "                          with rasterio.open(clipped_raster_path, \"w\", **out_meta) as dest:\n",
        "                              dest.write(out_image)\n",
        "\n",
        "                          src_ds = gdal.Open(clipped_raster_path)\n",
        "                          if src_ds is None:\n",
        "                              print(\"Failed to open the clipped raster file.\")\n",
        "                              return\n",
        "\n",
        "                          cols = src_ds.RasterXSize\n",
        "                          rows = src_ds.RasterYSize\n",
        "                          bands = src_ds.RasterCount\n",
        "\n",
        "                          driver = gdal.GetDriverByName(\"GTiff\")\n",
        "                          dst_ds = driver.Create(path_b, cols, rows, bands, gdal.GDT_Float32)\n",
        "\n",
        "                          dst_ds.SetProjection(src_ds.GetProjection())\n",
        "                          dst_ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
        "\n",
        "                          for band_idx in range(1, bands + 1):\n",
        "                              band = src_ds.GetRasterBand(band_idx)\n",
        "                              band_array = band.ReadAsArray()\n",
        "\n",
        "                              mask_array = (band_array == -99999)\n",
        "\n",
        "                              masked_band_array = np.where(mask_array, np.nan, band_array)\n",
        "\n",
        "                              dst_band = dst_ds.GetRasterBand(band_idx)\n",
        "                              dst_band.WriteArray(masked_band_array)\n",
        "                          src_ds = None\n",
        "                          dst_ds = None\n",
        "                          os.remove(clipped_raster_path)\n",
        "\n",
        "                      clip_and_remove_zero_pixels(file_path,file_path,polygon_c)\n",
        "\n",
        "                      # main functionality on file path\n",
        "                      selected_bands=[2,3,4,8]\n",
        "                      with rasterio.open(file_path) as src:\n",
        "                          bands_data = src.read(selected_bands)\n",
        "                          width, height = src.width, src.height\n",
        "                          count = len(selected_bands)\n",
        "                          flat_data = bands_data.reshape((count, -1)).T\n",
        "                          column_names = [f'Band_{band}' for band in selected_bands]\n",
        "                          transform = src.transform\n",
        "                          srs = src.crs\n",
        "                          rows, cols = src.height, src.width\n",
        "                          y_coords, x_coords = [y for y in range(rows) for _ in range(cols)], [x for _ in range(rows) for x in range(cols)]\n",
        "                          pixel_coords = list(zip(y_coords, x_coords))\n",
        "                          lonlat_coords = [src.transform * (x, y) for y, x in pixel_coords]\n",
        "                          pixel_values_with_coords = [(lon, lat, *values) for (lon, lat), values in zip(lonlat_coords, flat_data)]\n",
        "                          column_names = ['Longitude', 'Latitude'] + column_names\n",
        "                          df = pd.DataFrame(pixel_values_with_coords, columns=column_names)\n",
        "\n",
        "                          for column in df.columns:\n",
        "                              df = df[df[column] != 0]\n",
        "\n",
        "                          # print(df.shape)\n",
        "                          df=df.reset_index()\n",
        "                          df=df.drop(columns={\"index\"})\n",
        "\n",
        "\n",
        "                          df.columns=[\"Longitude\",\"Latitude\",\"Band1\",\"Band2\",\"Band3\",\"Band4\"]\n",
        "\n",
        "                          X=df.iloc[:,2:]\n",
        "\n",
        "                          X[np.isinf(X)] = np.finfo(np.float32).max\n",
        "                          X[np.isnan(X)] = 0\n",
        "\n",
        "                          scaler = StandardScaler()\n",
        "                          X_test = scaler.fit_transform(X)\n",
        "\n",
        "                          #load the model\n",
        "                          # classes - 0 - canopy cover , 1 - no canopy\n",
        "\n",
        "                          #predictions\n",
        "                          ann_sc = tf.keras.models.load_model(config_data_stand_count[\"sc_ml_model\"])\n",
        "\n",
        "                          # predictions\n",
        "                          predictions_ann=ann_sc.predict(X_test)\n",
        "                          # argument=np.argmax(predictions_ann,axis=1)\n",
        "                          argument=np.where(predictions_ann < 0.5, 0, 1)\n",
        "\n",
        "                          total_1=np.count_nonzero(argument==1)\n",
        "                          total_0=np.count_nonzero(argument==0)\n",
        "\n",
        "                          pixel_resolution=10*10\n",
        "                          total_pixel_counts=total_0+total_1\n",
        "                          total_area_m2=total_pixel_counts*pixel_resolution\n",
        "                          total_area_acres=total_area_m2/4046.86\n",
        "                          canopy_cover_area_m2=total_0*pixel_resolution\n",
        "                          canopy_cover_area_acres=canopy_cover_area_m2/4046.86\n",
        "\n",
        "                          #calculations\n",
        "\n",
        "                          def area_converter(A):\n",
        "                            b=str(A).split('.')\n",
        "                            num1=b[0]+'.'+b[1][:3]\n",
        "                            if float(b[1][1][:3]) < 5.0:\n",
        "                              num1=b[0]+'.'+b[1][:3]\n",
        "                              num1=float(num1)\n",
        "                              num1=np.round(num1,2)\n",
        "                              return num1\n",
        "                            else:\n",
        "                              num1=b[0]+'.'+b[1][:3]\n",
        "                              num2=num1[:num1.find(num1.replace(num1[-1],\" \"))]\n",
        "                              num2=num2.strip()\n",
        "                              num2=float(num2)\n",
        "                              return num2\n",
        "\n",
        "                          # back up -- >>\n",
        "                          # def restrict_round(c):\n",
        "                          #   c=str(c)\n",
        "                          #   b=c[c.find('.')-c.find('.'):c.find('.')+2]\n",
        "                          #   b=float(b)\n",
        "                          #   return b\n",
        "\n",
        "                          canopy_cover_area_acres=area_converter(canopy_cover_area_acres)\n",
        "                          stand_count=canopy_cover_area_m2/spacing\n",
        "                          stand_count=int(np.round(stand_count,2))\n",
        "\n",
        "                          plant_density=stand_count/canopy_cover_area_acres\n",
        "                          plant_density=float(np.round(plant_density,1))\n",
        "\n",
        "                          recommended_plants=total_area_m2/spacing\n",
        "                          recommended_plants=int(np.round(recommended_plants))\n",
        "\n",
        "                          planned_seedling_density= recommended_plants/canopy_cover_area_acres\n",
        "                          planned_seedling_density=float(np.round(planned_seedling_density,1))\n",
        "\n",
        "                          recommended_plants=int(np.round(recommended_plants))\n",
        "                          stand_count=int(np.round(stand_count))\n",
        "\n",
        "\n",
        "                          difference=recommended_plants-stand_count\n",
        "                          under_norm=difference/recommended_plants\n",
        "                          under_norm=area_converter(under_norm)*100\n",
        "\n",
        "                          #bar chart\n",
        "                          labels = ['Recommended7 Plants', 'Stand Count']\n",
        "                          values = [recommended_plants, stand_count]\n",
        "                          colors = ['green', 'blue']\n",
        "                          # plt.figure(figsize=(7,5))\n",
        "                          # ax = sns.barplot(x=labels, y=values, palette=colors)\n",
        "                          # plt.title('Stand Cout Analysis')\n",
        "                          # plt.yticks([])\n",
        "                          # for i, value in enumerate(values):\n",
        "                          #     ax.text(i, value + 0.5, f'{value:,}', ha='center', va='bottom')\n",
        "                          # plt.savefig(f\"output/potato_stand_count/stand_count_bar_chart_{save_date}.jpg\")\n",
        "                          # plt.close()\n",
        "\n",
        "                          # creating the map\n",
        "                          pred_df= pd.DataFrame(argument,columns=['pred'])\n",
        "                          df_lat_long=pd.concat([df['Longitude'],df['Latitude'],pred_df['pred']],axis=1)\n",
        "                          geometry = [Point(xy) for xy in zip(df_lat_long ['Longitude'], df_lat_long ['Latitude'])]\n",
        "                          gdf = gpd.GeoDataFrame(df_lat_long , crs=\"EPSG:4326\", geometry=geometry)\n",
        "                          # print(gdf)\n",
        "                          colors = {0: 'orange', 1: 'purple'}\n",
        "                          labels={'Plants':'orange','No Plants':'purple'}\n",
        "                          ax = gdf.plot(color=[colors[val] for val in gdf['pred']], legend=True)\n",
        "\n",
        "                          plt.title('Stand Count Map')\n",
        "                          ax.set_xlabel('')\n",
        "                          ax.set_ylabel('')\n",
        "                          ax.set_xticks([])\n",
        "                          ax.set_yticks([])\n",
        "\n",
        "                          handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=15, label=label) for label, color in labels.items()]\n",
        "                          ax.legend(handles=handles, title='Legend', title_fontsize='large', loc='upper center', bbox_to_anchor=(0.5, -0.01), fancybox=True, shadow=True, ncol=2)\n",
        "\n",
        "                          fig = plt.gcf()\n",
        "                          fig.set_size_inches(6, 6)\n",
        "                          map_rel_path=cc_output_directory+\"/stand_count_map_\"\n",
        "                          map_path = f\"{map_rel_path}{save_date}.jpg\"\n",
        "                          plt.savefig(map_path,dpi=500)\n",
        "                          plt.close()\n",
        "\n",
        "                          #json file path\n",
        "                          output_rel_path=cc_output_directory+\"/stand_count_output_\"\n",
        "                          canopy_cover_output_json_path=f\"{output_rel_path}{save_date}.json\"\n",
        "\n",
        "                          # date conversion dd-mm-yy\n",
        "                          # analysis_date=datetime.strptime(analysis_date,'%Y-%m-%d').strftime('%d-%m-%Y')\n",
        "                          sowing_date=datetime.strptime(sowing_date,'%Y-%m-%d').strftime('%d-%m-%Y')\n",
        "                          all_data={\n",
        "                                      \"reportFor\":\"plant_stand_count\",\n",
        "                                      \"name\": org_name,\n",
        "                                      \"crop_name\": crop_name,\n",
        "                                      \"service Name\": service_name,\n",
        "                                      \"analysis_date\": analysis_date,\n",
        "                                      \"sowing_date\": sowing_date,\n",
        "                                      \"crop_area\": area_converter(total_area_acres),\n",
        "                                      \"PLANTS COUNTED\": stand_count,\n",
        "                                      \"PLANT DENSITY PER ACRE\": plant_density,\n",
        "                                      \"PLANNED SEEDLING DENSITY PER ACRE\": planned_seedling_density,\n",
        "                                      \"plants in percentages\": f\"{under_norm}%\",\n",
        "                                      \"The total Plants under the norm is\": difference,\n",
        "                                      \"bar\":[{\n",
        "                                      \"rowKey\":\"Recomended Plant\",\n",
        "                                      \"rowvalue\":recommended_plants\n",
        "                                      },{\n",
        "                                      \"rowKey\":\"Stand Plant\",\n",
        "                                      \"rowvalue\":stand_count\n",
        "                                      }],\n",
        "                                      \"map\":f\"stand_count_map_{save_date}.jpg\"\n",
        "                          }\n",
        "\n",
        "\n",
        "                      with open(canopy_cover_output_json_path, 'w') as json_file:\n",
        "                          json.dump(all_data, json_file, indent=4)\n",
        "\n",
        "                      # cleared the tiff file from folder\n",
        "                      def clear_directory(directory_path):\n",
        "                          shutil.rmtree(directory_path, ignore_errors=True)\n",
        "                          os.makedirs(directory_path)\n",
        "\n",
        "                      directory_path_to_clear=config_data_main[\"data_output_folder\"]\n",
        "                      clear_directory(directory_path_to_clear)\n",
        "\n",
        "                      return canopy_cover_output_json_path\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error reading TIFF file: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main processing ErroR Might be due to Satellite image or directory in which image is getting stored : {e}\")\n",
        "\n",
        "\n",
        "def main(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing):\n",
        "\n",
        "  try:\n",
        "\n",
        "    # org_name ='abc'\n",
        "    # crop_name=data['crop_name']\n",
        "    # sowing_date=data['showing_date']\n",
        "    # service_name=data['service_name']\n",
        "    # analysis_date=data['analysis_date']\n",
        "    # polygon_c=data['geom']\n",
        "    # input_spacing=data['spacing']\n",
        "    stand_count_output=standcount(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing)\n",
        "    print(stand_count_output)\n",
        "\n",
        "  except:\n",
        "      print(\"Service Unavailable at this moment\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    input_spacing=\"0.15*0.20\"\n",
        "    analysis_date = \"2023-12-25\"\n",
        "    polygon_c=[[73.09556979663124, 23.8405276975719],\n",
        "            [73.10241918097321, 23.84029256809925],\n",
        "            [73.10268407569515, 23.83403065470798],\n",
        "            [73.0957683354565, 23.83407320230542],\n",
        "            [73.09556979663124, 23.8405276975719]]\n",
        "    org_name='abc'\n",
        "    crop_name=\"potato\"\n",
        "    sowing_date='2023-12-18'\n",
        "    service_name='Stand Count'\n",
        "    # data = json.loads(sys.argv[1])\n",
        "    try:\n",
        "        main(org_name,crop_name,sowing_date,service_name,analysis_date,polygon_c,input_spacing)\n",
        "    except:\n",
        "        print(\"internal error\")\n"
      ],
      "metadata": {
        "id": "71HMs811ssFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54977bf0-fc3c-464f-ba5a-fd1d06bbd7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rasterio._env:CPLE_AppDefined in temp_dir/e11ebaa7204e2b9d0103ea60e541e020/response.tiff: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
            "WARNING:rasterio._env:CPLE_AppDefined in TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154/154 [==============================] - 0s 2ms/step\n",
            "/root/agri_crop/image/potato/stand_count/stand_count_output_2024-04-22-10-04-1713782452.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhHeiyK_YYjX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}